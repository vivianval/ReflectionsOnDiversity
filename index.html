
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reflections on Diversity</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <header>
        <h1>Reflections on Diversity</h1>
        <h2>A Real-time Virtual Mirror for Inclusive 3D Face Transformations</h2>
        <p>Paraskevi Valergaki, Antonis Argyros, Giorgos Giannakakis, and Anastasios Roussos</p>
    </header>

    <section id="abstract">
        <h2>Abstract</h2>
        <p>
            Real-time 3D face manipulation has significant applications in virtual reality, social media and human-computer interaction. This paper introduces a novel system, which we call Mirror of Diversity (MOD), that combines Generative Adversarial Networks (GANs) for texture manipulation and 3D Morphable Models (3DMMs) for facial geometry to achieve realistic face transformations that reflect various demographic characteristics, emphasizing the beauty of diversity and the universality of human features. As participants sit in front of a computer monitor with a camera positioned above, their facial characteristics are captured in real time. Our system provides a dynamic, responsive “mirror” effect, allowing the digital 3D model to follow the participant’s motions, offering an immersive virtual reflection.
Participants can further alter their digital face reconstruction with transformations reflecting different demographic characteristics—such as gender and ethnicity (e.g., a person from Africa, Asia, Europe). 
Another feature of our system, which we call "Collective Face", generates an averaged face representation from multiple participants’ facial data. As each new face is processed, identity coefficients and textures are averaged to continuously update this collective face.
A comprehensive evaluation protocol is implemented to assess the realism
and demographic accuracy of the transformations. Qualitative feedback
is gathered through participant questionnaires, which include comparisons
of MOD transformations with similar filters on platforms like Snapchat and TikTok, focusing on realism, feature preservation, and faithfulness to demographic representation. Additionally, quantitative analysis is conducted using a pretrained Convolutional Neural Network that predicts gender and ethnicity, to validate the accuracy of demographic transformations.
        </p>
    </section>

    <section id="video">
        <h2>Video Demonstration</h2>
        <iframe width="800" height="450" src="https://www.youtube.com/embed/w2w6hz5Nf_I" frameborder="0" allowfullscreen></iframe>
    </section>

    <section id="paper">
        <h2>Paper</h2>
        <p><a href="LINK_TO_PAPER.pdf" target="_blank">Read the Paper (PDF)</a></p>
        <pre>
@article{valergaki2025reflections,
  author    = {Paraskevi Valergaki and Antonis Argyros and Giorgos Giannakakis and Anastasios Roussos},
  title     = {Reflections on Diversity: A Real-time Virtual Mirror for Inclusive 3D Face Transformations},
  journal   = {Conference/Journal Name},
  year      = {2025},
}
        </pre>
    </section>

    <footer>
        <p>© 2025 Reflections on Diversity | Developed for promoting diversity in AI and facial transformations.</p>
    </footer>

</body>
</html>
